{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTIVIDAD 1:\n",
    "## CATEGORÍAS GRAMATICALES Y EXTRACCIÓN DE ENTIDADES\n",
    "\n",
    "***\n",
    "\n",
    "### JOSE LÓPEZ GALDÓN\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guión de la actividad\n",
    "\n",
    "1. En esta actividad se le facilitan dos ficheros de texto, uno en español y otro en inglés. Son los ficheros **esp.txt** e **ing.txt**.\n",
    "\n",
    "2. Lea estos ficheros desde un programa Python, y realice las labores de pre-procesamiento habituales: división en frases, división en palabras y conversión a las formas normales. Utilice los frameworks que prefiera, se sugiere **NLTK** o **spaCy**.\n",
    "\n",
    "3. Realice un análisis morfológico (*POS, Part of Speech*) de los términos incluidos. \n",
    "\n",
    "4. Por último, extraiga entidades de los textos anteriores\n",
    "\n",
    "5. Una vez realizados todos los análisis, liste en pantalla las anotaciones obtenidas: frases, palabras, categoría gramatical del análisis morfológico, y entidades extraídas: localizaciones, organizaciones y personas.\n",
    "\n",
    "6. Comente las diferencias entre los resultados obtenidos en español y en inglés. ¿Hay diferencias entre utilizar **NLTK** y **spaCy**?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías\n",
    "Comenzamos cargando las librerías necesarias para este ejercicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:14.871730Z",
     "start_time": "2021-04-19T08:40:13.069526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importamos NLTK\n",
    "import nltk, re, pprint\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Importamos spaCy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Importamos pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizar DF\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga de ficheros\n",
    "\n",
    "Continuamos el ejercicio cargando ambos ficheros, tal y como nos indica la primera pregunta..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:14.886734Z",
     "start_time": "2021-04-19T08:40:14.872731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuando los cines parecen recuperar su músculo, llega a las salas de España la película \"Los Estados Unidos contra Billie Holiday\", el desalentador retrato del director Lee Daniels sobre la persecución del Gobierno Federal de Estados Unidos a la gran cantante de jazz desde 1947 hasta su muerte en 1959 a la edad de 44 años. El título de la cinta toma como referencia una frase de la artista, que ingresó en prisión durante un año por un cargo de posesión de narcóticos en el apogeo de su carrera: El caso se llama \"Los Estados Unidos de América contra Billie Holiday\". Está basado en un capítulo del libro \"Tras el grito\"\n",
      "\n",
      "This week, a Filipino woman was attacked in Midtown Manhattan during broad daylight. This assault came on the heels of the Atlanta-area shooting in which six women of Asian descent were killed and amid reports of rising crime against Asians. One group, Stop AAPI Hate, received nearly 3,800 accounts of incidents nationally between March 19, 2020, and Feb. 28. The poet and author Cathy Park Hong notes that these events have set off outrage in the Asian-American community. Her essay collection “Minor Feelings: An Asian-American Reckoning” wrestles with how discrimination against Asians is often left out in conversations about race in the United States. “We have also been victims to systemic racism throughout history,” Ms. Hong says, “but we have been conditioned to pretend that it doesn’t exist, to minimize it.”\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los ficheros con NLTK\n",
    "# Primero el fichero español\n",
    "esp_NLTK = open(\"esp.txt\", \"r\", encoding=\"utf8\").read()\n",
    "print(esp_NLTK)\n",
    "\n",
    "# En segundo lugar, el fichero en inglés\n",
    "eng_NLTK = open(\"ing.txt\",\"r\", encoding=\"utf8\").read()\n",
    "print(eng_NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:16.631096Z",
     "start_time": "2021-04-19T08:40:14.887733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuando los cines parecen recuperar su músculo, llega a las salas de España la película \"Los Estados Unidos contra Billie Holiday\", el desalentador retrato del director Lee Daniels sobre la persecución del Gobierno Federal de Estados Unidos a la gran cantante de jazz desde 1947 hasta su muerte en 1959 a la edad de 44 años. El título de la cinta toma como referencia una frase de la artista, que ingresó en prisión durante un año por un cargo de posesión de narcóticos en el apogeo de su carrera: El caso se llama \"Los Estados Unidos de América contra Billie Holiday\". Está basado en un capítulo del libro \"Tras el grito\"\n",
      "\n",
      "This week, a Filipino woman was attacked in Midtown Manhattan during broad daylight. This assault came on the heels of the Atlanta-area shooting in which six women of Asian descent were killed and amid reports of rising crime against Asians. One group, Stop AAPI Hate, received nearly 3,800 accounts of incidents nationally between March 19, 2020, and Feb. 28. The poet and author Cathy Park Hong notes that these events have set off outrage in the Asian-American community. Her essay collection “Minor Feelings: An Asian-American Reckoning” wrestles with how discrimination against Asians is often left out in conversations about race in the United States. “We have also been victims to systemic racism throughout history,” Ms. Hong says, “but we have been conditioned to pretend that it doesn’t exist, to minimize it.”\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los ficheros con spaCy, para ello deberemos cargar los idiomas\n",
    "nlp_es = spacy.load('es_core_news_md')\n",
    "nlp_eng = spacy.load('en_core_web_md')\n",
    "\n",
    "# Primero el fichero español\n",
    "esp_spacy = open(\"esp.txt\", \"r\", encoding=\"utf8\").read()\n",
    "print(esp_spacy)\n",
    "\n",
    "# En segundo lugar, el fichero en inglés\n",
    "eng_spacy = open(\"ing.txt\",\"r\", encoding=\"utf8\").read()\n",
    "print(eng_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ambos ficheros se cargan perfectamente con las dos librerías, sin embargo, la lectura con spacy ha sido más lenta... Uno de los motivos que expliquen esto es que hemos tenido que cargar los idiomas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T16:55:22.065299Z",
     "start_time": "2021-04-17T16:55:22.050593Z"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-procesamiento\n",
    "\n",
    "División en frases, división en palabras y conversión a las formas normales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### División en frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:16.647091Z",
     "start_time": "2021-04-19T08:40:16.632087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "División en frases del documento en español\n",
      "Cuando los cines parecen recuperar su músculo, llega a las salas de España la película \"Los Estados Unidos contra Billie Holiday\", el desalentador retrato del director Lee Daniels sobre la persecución del Gobierno Federal de Estados Unidos a la gran cantante de jazz desde 1947 hasta su muerte en 1959 a la edad de 44 años.\n",
      "El título de la cinta toma como referencia una frase de la artista, que ingresó en prisión durante un año por un cargo de posesión de narcóticos en el apogeo de su carrera: El caso se llama \"Los Estados Unidos de América contra Billie Holiday\".\n",
      "Está basado en un capítulo del libro \"Tras el grito\"\n"
     ]
    }
   ],
   "source": [
    "# División en frases con NLTK (español)\n",
    "print(\"División en frases del documento en español\")\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "sents = sent_tokenizer.tokenize(esp_NLTK)\n",
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:16.662093Z",
     "start_time": "2021-04-19T08:40:16.648091Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "División en frases del documento en inglés\n",
      "This week, a Filipino woman was attacked in Midtown Manhattan during broad daylight.\n",
      "This assault came on the heels of the Atlanta-area shooting in which six women of Asian descent were killed and amid reports of rising crime against Asians.\n",
      "One group, Stop AAPI Hate, received nearly 3,800 accounts of incidents nationally between March 19, 2020, and Feb. 28.\n",
      "The poet and author Cathy Park Hong notes that these events have set off outrage in the Asian-American community.\n",
      "Her essay collection “Minor Feelings: An Asian-American Reckoning” wrestles with how discrimination against Asians is often left out in conversations about race in the United States.\n",
      "“We have also been victims to systemic racism throughout history,” Ms. Hong says, “but we have been conditioned to pretend that it doesn’t exist, to minimize it.”\n"
     ]
    }
   ],
   "source": [
    "# División en frases con NLTK (inglés)   \n",
    "print(\"División en frases del documento en inglés\")\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "sents = sent_tokenizer.tokenize(eng_NLTK)\n",
    "for sent in sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ambos casos, separa correctamente por frases (a partir del signo puntuación \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:16.725123Z",
     "start_time": "2021-04-19T08:40:16.663093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuando los cines parecen recuperar su músculo, llega a las salas de España la película \"Los Estados Unidos contra Billie Holiday\", el desalentador retrato del director Lee Daniels sobre la persecución del Gobierno Federal de Estados Unidos a la gran cantante de jazz desde 1947 hasta su muerte en 1959 a la edad de 44 años.\n",
      "El título de la cinta toma como referencia una frase de la artista, que ingresó en prisión durante un año por un cargo de posesión de narcóticos en el apogeo de su carrera: El caso se llama \"Los Estados Unidos de América contra Billie Holiday\".\n",
      "Está basado en un capítulo del libro \"Tras el grito\"\n",
      "\n",
      "This week, a Filipino woman was attacked in Midtown Manhattan during broad daylight.\n",
      "This assault came on the heels of the Atlanta-area shooting in which six women of Asian descent were killed and amid reports of rising crime against Asians.\n",
      "One group, Stop AAPI Hate, received nearly 3,800 accounts of incidents nationally between March 19, 2020, and Feb. 28.\n",
      "The poet and author Cathy Park Hong notes that these events have set off outrage in the Asian-American community.\n",
      "Her essay collection “Minor Feelings: An Asian-American Reckoning” wrestles with how discrimination against Asians is often left out in conversations about race in the United States.\n",
      "“We have also been victims to systemic racism throughout history,” Ms. Hong says, “but we have been conditioned to pretend that it doesn’t exist, to minimize it.”\n"
     ]
    }
   ],
   "source": [
    "# División en frases SPACY\n",
    "# Ejecutamos la pipeline de análisis\n",
    "docum_analizado = nlp_es(esp_spacy)\n",
    "docum_analyzed = nlp_eng(eng_spacy)\n",
    "\n",
    "# Imprimimos frases\n",
    "for sent in docum_analizado.sents:\n",
    "    print(sent.text)\n",
    "    \n",
    "for sent_eng in docum_analyzed.sents:\n",
    "    print(sent_eng.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con NLTK separa correctamente por frases ambos idiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### División por palabras (tokennización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:16.741131Z",
     "start_time": "2021-04-19T08:40:16.726125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens texto español\n",
      "['Cuando', 'los', 'cines', 'parecen', 'recuperar', 'su', 'músculo', ',', 'llega', 'a', 'las', 'salas', 'de', 'España', 'la']\n"
     ]
    }
   ],
   "source": [
    "# Tokennización en español con NLTK\n",
    "print(\"Tokens texto español\")\n",
    "tokens_esp = nltk.word_tokenize(esp_NLTK)\n",
    "\n",
    "# Imprimimos los primeros 15 tokes para ver si lo realiza correctamente\n",
    "print(tokens_esp[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:16.757135Z",
     "start_time": "2021-04-19T08:40:16.742132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens texto inglés\n",
      "['This', 'week', ',', 'a', 'Filipino', 'woman', 'was', 'attacked', 'in', 'Midtown', 'Manhattan', 'during', 'broad', 'daylight', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokennización en inglés con NLTK\n",
    "print(\"Tokens texto inglés\")\n",
    "tokens_eng = nltk.word_tokenize(eng_NLTK)\n",
    "\n",
    "# Imprimimos los primeros 15 tokes para ver si lo realiza correctamente\n",
    "print(tokens_eng[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que ambos casos detecta bien los tokens..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lematiazación (división por formas normales o canónicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:17.928922Z",
     "start_time": "2021-04-19T08:40:16.758136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemas en español\n",
      "\n",
      "Cuando\n",
      "los\n",
      "cines\n",
      "parecen\n",
      "recuperar\n",
      "su\n",
      "músculo\n",
      ",\n",
      "llega\n",
      "a\n",
      "las\n",
      "salas\n",
      "de\n",
      "España\n",
      "la\n",
      "película\n",
      "``\n",
      "Los\n",
      "Estados\n",
      "Unidos\n",
      "contra\n",
      "Billie\n",
      "Holiday\n",
      "''\n",
      ",\n",
      "el\n",
      "desalentador\n",
      "retrato\n",
      "del\n",
      "director\n",
      "Lee\n",
      "Daniels\n",
      "sobre\n",
      "la\n",
      "persecución\n",
      "del\n",
      "Gobierno\n",
      "Federal\n",
      "de\n",
      "Estados\n",
      "Unidos\n",
      "a\n",
      "la\n",
      "gran\n",
      "cantante\n",
      "de\n",
      "jazz\n",
      "desde\n",
      "1947\n",
      "hasta\n",
      "su\n",
      "muerte\n",
      "en\n",
      "1959\n",
      "a\n",
      "la\n",
      "edad\n",
      "de\n",
      "44\n",
      "años\n",
      ".\n",
      "El\n",
      "título\n",
      "de\n",
      "la\n",
      "cinta\n",
      "toma\n",
      "como\n",
      "referencia\n",
      "una\n",
      "frase\n",
      "de\n",
      "la\n",
      "artista\n",
      ",\n",
      "que\n",
      "ingresó\n",
      "en\n",
      "prisión\n",
      "durante\n",
      "un\n",
      "año\n",
      "por\n",
      "un\n",
      "cargo\n",
      "de\n",
      "posesión\n",
      "de\n",
      "narcóticos\n",
      "en\n",
      "el\n",
      "apogeo\n",
      "de\n",
      "su\n",
      "carrera\n",
      ":\n",
      "El\n",
      "caso\n",
      "se\n",
      "llama\n",
      "``\n",
      "Los\n",
      "Estados\n",
      "Unidos\n",
      "de\n",
      "América\n",
      "contra\n",
      "Billie\n",
      "Holiday\n",
      "''\n",
      ".\n",
      "Está\n",
      "basado\n",
      "en\n",
      "un\n",
      "capítulo\n",
      "del\n",
      "libro\n",
      "``\n",
      "Tras\n",
      "el\n",
      "grito\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "# Lematización con NLTK en español\n",
    "print(\"\")\n",
    "print(\"Lemas en español\")\n",
    "print(\"\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "for token in tokens_esp:\n",
    "    print(wordnet_lemmatizer.lemmatize(token, pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:17.944927Z",
     "start_time": "2021-04-19T08:40:17.929924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemas en inglés\n",
      "\n",
      "This\n",
      "week\n",
      ",\n",
      "a\n",
      "Filipino\n",
      "woman\n",
      "be\n",
      "attack\n",
      "in\n",
      "Midtown\n",
      "Manhattan\n",
      "during\n",
      "broad\n",
      "daylight\n",
      ".\n",
      "This\n",
      "assault\n",
      "come\n",
      "on\n",
      "the\n",
      "heel\n",
      "of\n",
      "the\n",
      "Atlanta-area\n",
      "shoot\n",
      "in\n",
      "which\n",
      "six\n",
      "women\n",
      "of\n",
      "Asian\n",
      "descent\n",
      "be\n",
      "kill\n",
      "and\n",
      "amid\n",
      "report\n",
      "of\n",
      "rise\n",
      "crime\n",
      "against\n",
      "Asians\n",
      ".\n",
      "One\n",
      "group\n",
      ",\n",
      "Stop\n",
      "AAPI\n",
      "Hate\n",
      ",\n",
      "receive\n",
      "nearly\n",
      "3,800\n",
      "account\n",
      "of\n",
      "incidents\n",
      "nationally\n",
      "between\n",
      "March\n",
      "19\n",
      ",\n",
      "2020\n",
      ",\n",
      "and\n",
      "Feb.\n",
      "28\n",
      ".\n",
      "The\n",
      "poet\n",
      "and\n",
      "author\n",
      "Cathy\n",
      "Park\n",
      "Hong\n",
      "note\n",
      "that\n",
      "these\n",
      "events\n",
      "have\n",
      "set\n",
      "off\n",
      "outrage\n",
      "in\n",
      "the\n",
      "Asian-American\n",
      "community\n",
      ".\n",
      "Her\n",
      "essay\n",
      "collection\n",
      "“\n",
      "Minor\n",
      "Feelings\n",
      ":\n",
      "An\n",
      "Asian-American\n",
      "Reckoning\n",
      "”\n",
      "wrestle\n",
      "with\n",
      "how\n",
      "discrimination\n",
      "against\n",
      "Asians\n",
      "be\n",
      "often\n",
      "leave\n",
      "out\n",
      "in\n",
      "conversations\n",
      "about\n",
      "race\n",
      "in\n",
      "the\n",
      "United\n",
      "States\n",
      ".\n",
      "“\n",
      "We\n",
      "have\n",
      "also\n",
      "be\n",
      "victims\n",
      "to\n",
      "systemic\n",
      "racism\n",
      "throughout\n",
      "history\n",
      ",\n",
      "”\n",
      "Ms.\n",
      "Hong\n",
      "say\n",
      ",\n",
      "“\n",
      "but\n",
      "we\n",
      "have\n",
      "be\n",
      "condition\n",
      "to\n",
      "pretend\n",
      "that\n",
      "it\n",
      "doesn\n",
      "’\n",
      "t\n",
      "exist\n",
      ",\n",
      "to\n",
      "minimize\n",
      "it\n",
      ".\n",
      "”\n"
     ]
    }
   ],
   "source": [
    "# Lematización con NLTK en español\n",
    "print(\"\")\n",
    "print(\"Lemas en inglés\")\n",
    "print(\"\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "for token in tokens_eng:\n",
    "    print(wordnet_lemmatizer.lemmatize(token, pos=\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos obeservar la lematización en inglés se realiza correctamente, ya que cambia a las formas canónicas o normales, como es el caso del verbo *be*. Sin embargo, en español no parece funcionar correctamente, ya que mantiene las formas verbales origninales..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis morfológico\n",
    "\n",
    "POS, *Part of Speech*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:17.992942Z",
     "start_time": "2021-04-19T08:40:17.945927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Palabra</th>\n",
       "      <td>Cuando</td>\n",
       "      <td>los</td>\n",
       "      <td>cines</td>\n",
       "      <td>parecen</td>\n",
       "      <td>recuperar</td>\n",
       "      <td>su</td>\n",
       "      <td>músculo</td>\n",
       "      <td>,</td>\n",
       "      <td>llega</td>\n",
       "      <td>a</td>\n",
       "      <td>las</td>\n",
       "      <td>salas</td>\n",
       "      <td>de</td>\n",
       "      <td>España</td>\n",
       "      <td>la</td>\n",
       "      <td>película</td>\n",
       "      <td>\"</td>\n",
       "      <td>Los</td>\n",
       "      <td>Estados</td>\n",
       "      <td>Unidos</td>\n",
       "      <td>contra</td>\n",
       "      <td>Billie</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>\"</td>\n",
       "      <td>,</td>\n",
       "      <td>el</td>\n",
       "      <td>desalentador</td>\n",
       "      <td>retrato</td>\n",
       "      <td>del</td>\n",
       "      <td>director</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Daniels</td>\n",
       "      <td>sobre</td>\n",
       "      <td>la</td>\n",
       "      <td>persecución</td>\n",
       "      <td>del</td>\n",
       "      <td>Gobierno</td>\n",
       "      <td>Federal</td>\n",
       "      <td>de</td>\n",
       "      <td>Estados</td>\n",
       "      <td>Unidos</td>\n",
       "      <td>a</td>\n",
       "      <td>la</td>\n",
       "      <td>gran</td>\n",
       "      <td>cantante</td>\n",
       "      <td>de</td>\n",
       "      <td>jazz</td>\n",
       "      <td>desde</td>\n",
       "      <td>1947</td>\n",
       "      <td>hasta</td>\n",
       "      <td>su</td>\n",
       "      <td>muerte</td>\n",
       "      <td>en</td>\n",
       "      <td>1959</td>\n",
       "      <td>a</td>\n",
       "      <td>la</td>\n",
       "      <td>edad</td>\n",
       "      <td>de</td>\n",
       "      <td>44</td>\n",
       "      <td>años</td>\n",
       "      <td>.</td>\n",
       "      <td>El</td>\n",
       "      <td>título</td>\n",
       "      <td>de</td>\n",
       "      <td>la</td>\n",
       "      <td>cinta</td>\n",
       "      <td>toma</td>\n",
       "      <td>como</td>\n",
       "      <td>referencia</td>\n",
       "      <td>una</td>\n",
       "      <td>frase</td>\n",
       "      <td>de</td>\n",
       "      <td>la</td>\n",
       "      <td>artista</td>\n",
       "      <td>,</td>\n",
       "      <td>que</td>\n",
       "      <td>ingresó</td>\n",
       "      <td>en</td>\n",
       "      <td>prisión</td>\n",
       "      <td>durante</td>\n",
       "      <td>un</td>\n",
       "      <td>año</td>\n",
       "      <td>por</td>\n",
       "      <td>un</td>\n",
       "      <td>cargo</td>\n",
       "      <td>de</td>\n",
       "      <td>posesión</td>\n",
       "      <td>de</td>\n",
       "      <td>narcóticos</td>\n",
       "      <td>en</td>\n",
       "      <td>el</td>\n",
       "      <td>apogeo</td>\n",
       "      <td>de</td>\n",
       "      <td>su</td>\n",
       "      <td>carrera</td>\n",
       "      <td>:</td>\n",
       "      <td>El</td>\n",
       "      <td>caso</td>\n",
       "      <td>se</td>\n",
       "      <td>llama</td>\n",
       "      <td>\"</td>\n",
       "      <td>Los</td>\n",
       "      <td>Estados</td>\n",
       "      <td>Unidos</td>\n",
       "      <td>de</td>\n",
       "      <td>América</td>\n",
       "      <td>contra</td>\n",
       "      <td>Billie</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>\"</td>\n",
       "      <td>.</td>\n",
       "      <td>Está</td>\n",
       "      <td>basado</td>\n",
       "      <td>en</td>\n",
       "      <td>un</td>\n",
       "      <td>capítulo</td>\n",
       "      <td>del</td>\n",
       "      <td>libro</td>\n",
       "      <td>\"</td>\n",
       "      <td>Tras</td>\n",
       "      <td>el</td>\n",
       "      <td>grito</td>\n",
       "      <td>\"</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forma Canónica</th>\n",
       "      <td>cuando</td>\n",
       "      <td>el</td>\n",
       "      <td>cine</td>\n",
       "      <td>parecer</td>\n",
       "      <td>recuperar</td>\n",
       "      <td>su</td>\n",
       "      <td>músculo</td>\n",
       "      <td>,</td>\n",
       "      <td>llegar</td>\n",
       "      <td>a</td>\n",
       "      <td>el</td>\n",
       "      <td>sala</td>\n",
       "      <td>de</td>\n",
       "      <td>España</td>\n",
       "      <td>el</td>\n",
       "      <td>película</td>\n",
       "      <td>\"</td>\n",
       "      <td>el</td>\n",
       "      <td>Estados</td>\n",
       "      <td>Unidos</td>\n",
       "      <td>contra</td>\n",
       "      <td>Billie</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>\"</td>\n",
       "      <td>,</td>\n",
       "      <td>el</td>\n",
       "      <td>desalentador</td>\n",
       "      <td>retrato</td>\n",
       "      <td>del</td>\n",
       "      <td>director</td>\n",
       "      <td>Lee</td>\n",
       "      <td>Daniels</td>\n",
       "      <td>sobre</td>\n",
       "      <td>el</td>\n",
       "      <td>persecución</td>\n",
       "      <td>del</td>\n",
       "      <td>Gobierno</td>\n",
       "      <td>Federal</td>\n",
       "      <td>de</td>\n",
       "      <td>Estados</td>\n",
       "      <td>Unidos</td>\n",
       "      <td>a</td>\n",
       "      <td>el</td>\n",
       "      <td>gran</td>\n",
       "      <td>cantante</td>\n",
       "      <td>de</td>\n",
       "      <td>jazz</td>\n",
       "      <td>desde</td>\n",
       "      <td>1947</td>\n",
       "      <td>hasta</td>\n",
       "      <td>su</td>\n",
       "      <td>muerte</td>\n",
       "      <td>en</td>\n",
       "      <td>1959</td>\n",
       "      <td>a</td>\n",
       "      <td>el</td>\n",
       "      <td>edad</td>\n",
       "      <td>de</td>\n",
       "      <td>44</td>\n",
       "      <td>año</td>\n",
       "      <td>.</td>\n",
       "      <td>el</td>\n",
       "      <td>título</td>\n",
       "      <td>de</td>\n",
       "      <td>el</td>\n",
       "      <td>cinta</td>\n",
       "      <td>tomar</td>\n",
       "      <td>como</td>\n",
       "      <td>referencia</td>\n",
       "      <td>uno</td>\n",
       "      <td>frase</td>\n",
       "      <td>de</td>\n",
       "      <td>el</td>\n",
       "      <td>artista</td>\n",
       "      <td>,</td>\n",
       "      <td>que</td>\n",
       "      <td>ingresar</td>\n",
       "      <td>en</td>\n",
       "      <td>prisión</td>\n",
       "      <td>durante</td>\n",
       "      <td>uno</td>\n",
       "      <td>año</td>\n",
       "      <td>por</td>\n",
       "      <td>uno</td>\n",
       "      <td>cargo</td>\n",
       "      <td>de</td>\n",
       "      <td>posesión</td>\n",
       "      <td>de</td>\n",
       "      <td>narcótico</td>\n",
       "      <td>en</td>\n",
       "      <td>el</td>\n",
       "      <td>apogeo</td>\n",
       "      <td>de</td>\n",
       "      <td>su</td>\n",
       "      <td>carrera</td>\n",
       "      <td>:</td>\n",
       "      <td>el</td>\n",
       "      <td>caso</td>\n",
       "      <td>él</td>\n",
       "      <td>llamar</td>\n",
       "      <td>\"</td>\n",
       "      <td>el</td>\n",
       "      <td>Estados</td>\n",
       "      <td>Unidos</td>\n",
       "      <td>de</td>\n",
       "      <td>América</td>\n",
       "      <td>contra</td>\n",
       "      <td>Billie</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>\"</td>\n",
       "      <td>.</td>\n",
       "      <td>estar</td>\n",
       "      <td>basado</td>\n",
       "      <td>en</td>\n",
       "      <td>uno</td>\n",
       "      <td>capítulo</td>\n",
       "      <td>del</td>\n",
       "      <td>libro</td>\n",
       "      <td>\"</td>\n",
       "      <td>Tras</td>\n",
       "      <td>el</td>\n",
       "      <td>grito</td>\n",
       "      <td>\"</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PRON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PRON</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>AUX</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imprimimos tokens, formas canónicas y entidades reconocidas para el documento en español\n",
    "\n",
    "# POS tagging with Spacy \n",
    "spacy_pos_tagged_esp = [(palabra.text, palabra.lemma_, palabra.pos_) for palabra in docum_analizado]\n",
    "POS_esp_df = pd.DataFrame(spacy_pos_tagged_esp, columns = ['Palabra', 'Forma Canónica', 'POS']).T\n",
    "\n",
    "# Imprimimos el DF completo\n",
    "display(HTML(POS_esp_df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:18.040953Z",
     "start_time": "2021-04-19T08:40:17.993943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Palabra</th>\n",
       "      <td>This</td>\n",
       "      <td>week</td>\n",
       "      <td>,</td>\n",
       "      <td>a</td>\n",
       "      <td>Filipino</td>\n",
       "      <td>woman</td>\n",
       "      <td>was</td>\n",
       "      <td>attacked</td>\n",
       "      <td>in</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>during</td>\n",
       "      <td>broad</td>\n",
       "      <td>daylight</td>\n",
       "      <td>.</td>\n",
       "      <td>This</td>\n",
       "      <td>assault</td>\n",
       "      <td>came</td>\n",
       "      <td>on</td>\n",
       "      <td>the</td>\n",
       "      <td>heels</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>-</td>\n",
       "      <td>area</td>\n",
       "      <td>shooting</td>\n",
       "      <td>in</td>\n",
       "      <td>which</td>\n",
       "      <td>six</td>\n",
       "      <td>women</td>\n",
       "      <td>of</td>\n",
       "      <td>Asian</td>\n",
       "      <td>descent</td>\n",
       "      <td>were</td>\n",
       "      <td>killed</td>\n",
       "      <td>and</td>\n",
       "      <td>amid</td>\n",
       "      <td>reports</td>\n",
       "      <td>of</td>\n",
       "      <td>rising</td>\n",
       "      <td>crime</td>\n",
       "      <td>against</td>\n",
       "      <td>Asians</td>\n",
       "      <td>.</td>\n",
       "      <td>One</td>\n",
       "      <td>group</td>\n",
       "      <td>,</td>\n",
       "      <td>Stop</td>\n",
       "      <td>AAPI</td>\n",
       "      <td>Hate</td>\n",
       "      <td>,</td>\n",
       "      <td>received</td>\n",
       "      <td>nearly</td>\n",
       "      <td>3,800</td>\n",
       "      <td>accounts</td>\n",
       "      <td>of</td>\n",
       "      <td>incidents</td>\n",
       "      <td>nationally</td>\n",
       "      <td>between</td>\n",
       "      <td>March</td>\n",
       "      <td>19</td>\n",
       "      <td>,</td>\n",
       "      <td>2020</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>Feb.</td>\n",
       "      <td>28</td>\n",
       "      <td>.</td>\n",
       "      <td>The</td>\n",
       "      <td>poet</td>\n",
       "      <td>and</td>\n",
       "      <td>author</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>Park</td>\n",
       "      <td>Hong</td>\n",
       "      <td>notes</td>\n",
       "      <td>that</td>\n",
       "      <td>these</td>\n",
       "      <td>events</td>\n",
       "      <td>have</td>\n",
       "      <td>set</td>\n",
       "      <td>off</td>\n",
       "      <td>outrage</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>Asian</td>\n",
       "      <td>-</td>\n",
       "      <td>American</td>\n",
       "      <td>community</td>\n",
       "      <td>.</td>\n",
       "      <td>Her</td>\n",
       "      <td>essay</td>\n",
       "      <td>collection</td>\n",
       "      <td>“</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Feelings</td>\n",
       "      <td>:</td>\n",
       "      <td>An</td>\n",
       "      <td>Asian</td>\n",
       "      <td>-</td>\n",
       "      <td>American</td>\n",
       "      <td>Reckoning</td>\n",
       "      <td>”</td>\n",
       "      <td>wrestles</td>\n",
       "      <td>with</td>\n",
       "      <td>how</td>\n",
       "      <td>discrimination</td>\n",
       "      <td>against</td>\n",
       "      <td>Asians</td>\n",
       "      <td>is</td>\n",
       "      <td>often</td>\n",
       "      <td>left</td>\n",
       "      <td>out</td>\n",
       "      <td>in</td>\n",
       "      <td>conversations</td>\n",
       "      <td>about</td>\n",
       "      <td>race</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>United</td>\n",
       "      <td>States</td>\n",
       "      <td>.</td>\n",
       "      <td>“</td>\n",
       "      <td>We</td>\n",
       "      <td>have</td>\n",
       "      <td>also</td>\n",
       "      <td>been</td>\n",
       "      <td>victims</td>\n",
       "      <td>to</td>\n",
       "      <td>systemic</td>\n",
       "      <td>racism</td>\n",
       "      <td>throughout</td>\n",
       "      <td>history</td>\n",
       "      <td>,</td>\n",
       "      <td>”</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Hong</td>\n",
       "      <td>says</td>\n",
       "      <td>,</td>\n",
       "      <td>“</td>\n",
       "      <td>but</td>\n",
       "      <td>we</td>\n",
       "      <td>have</td>\n",
       "      <td>been</td>\n",
       "      <td>conditioned</td>\n",
       "      <td>to</td>\n",
       "      <td>pretend</td>\n",
       "      <td>that</td>\n",
       "      <td>it</td>\n",
       "      <td>does</td>\n",
       "      <td>n’t</td>\n",
       "      <td>exist</td>\n",
       "      <td>,</td>\n",
       "      <td>to</td>\n",
       "      <td>minimize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forma Canónica</th>\n",
       "      <td>this</td>\n",
       "      <td>week</td>\n",
       "      <td>,</td>\n",
       "      <td>a</td>\n",
       "      <td>filipino</td>\n",
       "      <td>woman</td>\n",
       "      <td>be</td>\n",
       "      <td>attack</td>\n",
       "      <td>in</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>during</td>\n",
       "      <td>broad</td>\n",
       "      <td>daylight</td>\n",
       "      <td>.</td>\n",
       "      <td>this</td>\n",
       "      <td>assault</td>\n",
       "      <td>come</td>\n",
       "      <td>on</td>\n",
       "      <td>the</td>\n",
       "      <td>heel</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>-</td>\n",
       "      <td>area</td>\n",
       "      <td>shooting</td>\n",
       "      <td>in</td>\n",
       "      <td>which</td>\n",
       "      <td>six</td>\n",
       "      <td>woman</td>\n",
       "      <td>of</td>\n",
       "      <td>asian</td>\n",
       "      <td>descent</td>\n",
       "      <td>be</td>\n",
       "      <td>kill</td>\n",
       "      <td>and</td>\n",
       "      <td>amid</td>\n",
       "      <td>report</td>\n",
       "      <td>of</td>\n",
       "      <td>rise</td>\n",
       "      <td>crime</td>\n",
       "      <td>against</td>\n",
       "      <td>Asians</td>\n",
       "      <td>.</td>\n",
       "      <td>one</td>\n",
       "      <td>group</td>\n",
       "      <td>,</td>\n",
       "      <td>stop</td>\n",
       "      <td>AAPI</td>\n",
       "      <td>hate</td>\n",
       "      <td>,</td>\n",
       "      <td>receive</td>\n",
       "      <td>nearly</td>\n",
       "      <td>3,800</td>\n",
       "      <td>account</td>\n",
       "      <td>of</td>\n",
       "      <td>incident</td>\n",
       "      <td>nationally</td>\n",
       "      <td>between</td>\n",
       "      <td>March</td>\n",
       "      <td>19</td>\n",
       "      <td>,</td>\n",
       "      <td>2020</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>Feb.</td>\n",
       "      <td>28</td>\n",
       "      <td>.</td>\n",
       "      <td>the</td>\n",
       "      <td>poet</td>\n",
       "      <td>and</td>\n",
       "      <td>author</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>Park</td>\n",
       "      <td>Hong</td>\n",
       "      <td>note</td>\n",
       "      <td>that</td>\n",
       "      <td>these</td>\n",
       "      <td>event</td>\n",
       "      <td>have</td>\n",
       "      <td>set</td>\n",
       "      <td>off</td>\n",
       "      <td>outrage</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>asian</td>\n",
       "      <td>-</td>\n",
       "      <td>american</td>\n",
       "      <td>community</td>\n",
       "      <td>.</td>\n",
       "      <td>her</td>\n",
       "      <td>essay</td>\n",
       "      <td>collection</td>\n",
       "      <td>\"</td>\n",
       "      <td>minor</td>\n",
       "      <td>feeling</td>\n",
       "      <td>:</td>\n",
       "      <td>an</td>\n",
       "      <td>asian</td>\n",
       "      <td>-</td>\n",
       "      <td>american</td>\n",
       "      <td>reckoning</td>\n",
       "      <td>\"</td>\n",
       "      <td>wrestle</td>\n",
       "      <td>with</td>\n",
       "      <td>how</td>\n",
       "      <td>discrimination</td>\n",
       "      <td>against</td>\n",
       "      <td>Asians</td>\n",
       "      <td>be</td>\n",
       "      <td>often</td>\n",
       "      <td>leave</td>\n",
       "      <td>out</td>\n",
       "      <td>in</td>\n",
       "      <td>conversation</td>\n",
       "      <td>about</td>\n",
       "      <td>race</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>United</td>\n",
       "      <td>States</td>\n",
       "      <td>.</td>\n",
       "      <td>\"</td>\n",
       "      <td>we</td>\n",
       "      <td>have</td>\n",
       "      <td>also</td>\n",
       "      <td>be</td>\n",
       "      <td>victim</td>\n",
       "      <td>to</td>\n",
       "      <td>systemic</td>\n",
       "      <td>racism</td>\n",
       "      <td>throughout</td>\n",
       "      <td>history</td>\n",
       "      <td>,</td>\n",
       "      <td>\"</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Hong</td>\n",
       "      <td>say</td>\n",
       "      <td>,</td>\n",
       "      <td>\"</td>\n",
       "      <td>but</td>\n",
       "      <td>we</td>\n",
       "      <td>have</td>\n",
       "      <td>be</td>\n",
       "      <td>condition</td>\n",
       "      <td>to</td>\n",
       "      <td>pretend</td>\n",
       "      <td>that</td>\n",
       "      <td>it</td>\n",
       "      <td>do</td>\n",
       "      <td>n’t</td>\n",
       "      <td>exist</td>\n",
       "      <td>,</td>\n",
       "      <td>to</td>\n",
       "      <td>minimize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VERB</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NUM</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>NUM</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NUM</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>DET</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PRON</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>ADV</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>DET</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PRON</td>\n",
       "      <td>AUX</td>\n",
       "      <td>ADV</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PART</td>\n",
       "      <td>VERB</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>PRON</td>\n",
       "      <td>AUX</td>\n",
       "      <td>PART</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PART</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imprimimos tokens, formas canónicas y entidades reconocidas para el documento en inglés\n",
    "\n",
    "# POS tagging with Spacy \n",
    "spacy_eng_pos_tg = [(word.text, word.lemma_, word.pos_) for word in docum_analyzed]\n",
    "POS_eng_df = pd.DataFrame(spacy_eng_pos_tg, columns=['Palabra', 'Forma Canónica', 'POS']).T\n",
    "\n",
    "# Imprimimos el DF completo\n",
    "display(HTML(POS_eng_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con SpaCy hemos realizado el POS y la obtención por palabras y formas canónicas, a diferencia de NLTK vemos como si realiza correctamente la transformación de las formas canónicas, por lo que en este aspecto es mejor spaCy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:18.056957Z",
     "start_time": "2021-04-19T08:40:18.041953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entidad</th>\n",
       "      <td>España</td>\n",
       "      <td>Los Estados Unidos</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>Lee Daniels</td>\n",
       "      <td>Gobierno Federal de Estados Unidos</td>\n",
       "      <td>El título de la cinta</td>\n",
       "      <td>Los Estados Unidos</td>\n",
       "      <td>América</td>\n",
       "      <td>Billie Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo</th>\n",
       "      <td>LOC</td>\n",
       "      <td>LOC</td>\n",
       "      <td>MISC</td>\n",
       "      <td>PER</td>\n",
       "      <td>LOC</td>\n",
       "      <td>MISC</td>\n",
       "      <td>LOC</td>\n",
       "      <td>LOC</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0                   1               2            3  \\\n",
       "Entidad  España  Los Estados Unidos  Billie Holiday  Lee Daniels   \n",
       "Tipo        LOC                 LOC            MISC          PER   \n",
       "\n",
       "                                          4                      5  \\\n",
       "Entidad  Gobierno Federal de Estados Unidos  El título de la cinta   \n",
       "Tipo                                    LOC                   MISC   \n",
       "\n",
       "                          6        7               8  \n",
       "Entidad  Los Estados Unidos  América  Billie Holiday  \n",
       "Tipo                    LOC      LOC            MISC  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimimos las entidades en español\n",
    "\n",
    "ents_tagged_esp = [(ent.text, ent.label_) for ent in docum_analizado.ents]\n",
    "pd.DataFrame(ents_tagged_esp, columns=['Entidad', 'Tipo']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:18.072961Z",
     "start_time": "2021-04-19T08:40:18.057957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Entidad</th>\n",
       "      <td>This week</td>\n",
       "      <td>Filipino</td>\n",
       "      <td>Midtown Manhattan</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>six</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Asians</td>\n",
       "      <td>One</td>\n",
       "      <td>nearly 3,800</td>\n",
       "      <td>between March 19, 2020</td>\n",
       "      <td>Feb. 28</td>\n",
       "      <td>Cathy Park Hong</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Minor Feelings: An Asian-American Reckoning</td>\n",
       "      <td>Asians</td>\n",
       "      <td>the United States</td>\n",
       "      <td>Hong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo</th>\n",
       "      <td>DATE</td>\n",
       "      <td>NORP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>GPE</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NORP</td>\n",
       "      <td>NORP</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>DATE</td>\n",
       "      <td>DATE</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NORP</td>\n",
       "      <td>WORK_OF_ART</td>\n",
       "      <td>NORP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1                  2        3         4      5   \\\n",
       "Entidad  This week  Filipino  Midtown Manhattan  Atlanta       six  Asian   \n",
       "Tipo          DATE      NORP                GPE      GPE  CARDINAL   NORP   \n",
       "\n",
       "             6         7             8                       9        10  \\\n",
       "Entidad  Asians       One  nearly 3,800  between March 19, 2020  Feb. 28   \n",
       "Tipo       NORP  CARDINAL      CARDINAL                    DATE     DATE   \n",
       "\n",
       "                      11     12                                           13  \\\n",
       "Entidad  Cathy Park Hong  Asian  Minor Feelings: An Asian-American Reckoning   \n",
       "Tipo              PERSON   NORP                                  WORK_OF_ART   \n",
       "\n",
       "             14                 15      16  \n",
       "Entidad  Asians  the United States    Hong  \n",
       "Tipo       NORP                GPE  PERSON  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimimos las entidades en inglés\n",
    "\n",
    "ents_tagged_eng = [(ent.text, ent.label_) for ent in docum_analyzed.ents]\n",
    "pd.DataFrame(ents_tagged_eng, columns=['Entidad', 'Tipo']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que el texto en inglés contiene más entidades que el texto en castellano..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:18.088964Z",
     "start_time": "2021-04-19T08:40:18.073961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Cuando los cines parecen recuperar su músculo, llega a las salas de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " la película &quot;\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " contra \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Billie Holiday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       "&quot;, el desalentador retrato del director \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lee Daniels\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " sobre la persecución del \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gobierno Federal de Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " a la gran cantante de jazz desde 1947 hasta su muerte en 1959 a la edad de 44 años. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    El título de la cinta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " toma como referencia una frase de la artista, que ingresó en prisión durante un año por un cargo de posesión de narcóticos en el apogeo de su carrera: El caso se llama &quot;\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    América\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " contra \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Billie Holiday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       "&quot;. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlope\\anaconda3\\lib\\site-packages\\spacy\\displacy\\__init__.py:189: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Está basado en un capítulo del libro &quot;Tras el grito&quot;</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entidades en el texto español\n",
    "\n",
    "for sent in docum_analizado.sents:\n",
    "    displacy.render(sent, style='ent', jupyter=True, options={'distance': 110,'arrow_stroke': 2,'arrow_width': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T08:40:18.104968Z",
     "start_time": "2021-04-19T08:40:18.089965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    This week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", a \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Filipino\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " woman was attacked in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Midtown Manhattan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " during broad daylight. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This assault came on the heels of the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Atlanta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "-area shooting in which \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    six\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " women of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " descent were killed and amid reports of rising crime against \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " group, Stop AAPI Hate, received \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 3,800\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " accounts of incidents nationally \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    between March 19, 2020\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Feb. 28\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The poet and author \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cathy Park Hong\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " notes that these events have set off outrage in the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "-American community. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Her essay collection “\n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Minor Feelings: An Asian-American Reckoning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       "” wrestles with how discrimination against \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Asians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " is often left out in conversations about race in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">“We have also been victims to systemic racism throughout history,” Ms. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hong\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " says, “but we have been conditioned to pretend that it doesn’t exist, to minimize it.”</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entidades en el texto en inglés\n",
    "\n",
    "for sent in docum_analyzed.sents:\n",
    "    displacy.render(sent, style='ent', jupyter=True, options={'distance': 110,'arrow_stroke': 2,'arrow_width': 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el texto en inglés no nos da ningún tipo de error y detecta correctamente todas las entidades... Sin embargo, en el texto en español obtenemos un error y no reconoce las fechas como **DATE**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Hay diferencias entre utilizar `NLTK` y `spaCy`?\n",
    "\n",
    "Como hemos comentado a lo largo de estos ejercicos existen diferencias entre ambas librerías y entre los idiomas... En cuanto a los idiomas, ambas librerías funcionan perfectamente en Inglés. Sin embargo, en Español dan algunos problemas, por ejemplo:\n",
    "\n",
    "- En NLTK, no realiza la transformación de formas canónicas\n",
    "- En spaCy no detecta todas las entidades del texto, como es el caso de las fechas o cardinales\n",
    "\n",
    "A pesar de esto, la librería de spaCy funciona mejor en español que NLTK, por lo tanto, será nuestra preferencia a la hora de analizar textos en español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
